{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='Spectral',edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='Spectral')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='Spectral',edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for i, max_depth in enumerate([2, 4, None]):\n",
    "    for j, min_samples_leaf in enumerate([1, 5, 15]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((3, 3), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='Spectral')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='Spectral',edgecolors='k')\n",
    "        plt.title('max_depth=' + str(max_depth) + ', min_samples_leaf: ' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    indices = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indices], data_y[indices])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='Spectral')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='Spectral',edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "X_full = data.drop(columns=['MEDV'])\n",
    "y_full = data['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=100, \n",
    "                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor(random_state=42)\n",
    "print(-cross_val_score(regr, X, y, cv=cv, scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor(random_state=42)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor()\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor()\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(DecisionTreeRegressor(), n_estimators=10,\n",
    "                        bootstrap=False, random_state=42)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(DecisionTreeRegressor(), n_estimators=10,\n",
    "                        bootstrap=False, random_state=42,\n",
    "                        max_samples=0.7)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(DecisionTreeRegressor(), n_estimators=10,\n",
    "                        bootstrap=False, random_state=42,\n",
    "                        max_samples=0.5)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=10)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=300)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=500)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=1000)\n",
    "print(cross_val_score(regr, X, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.linspace(0, 1, 100)\n",
    "X_test = np.linspace(0, 1, 1000)\n",
    "\n",
    "def target(x):\n",
    "    return x > 0.5\n",
    "\n",
    "Y_train = target(X_train) + np.random.randn(*X_train.shape) * 0.1\n",
    "\n",
    "plt.figure(figsize = (16, 9))\n",
    "plt.scatter(X_train, Y_train, s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BaggingRegressor(DecisionTreeRegressor(max_depth=1), warm_start=True)\n",
    "plt.figure(figsize=(20, 30))\n",
    "sizes = [1, 2, 5, 20, 100, 500, 1000, 2000]\n",
    "for i, s in enumerate(sizes):\n",
    "    reg.n_estimators = s\n",
    "    reg.fit(X_train.reshape(-1, 1), Y_train)\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.scatter(X_train, Y_train, s=30)\n",
    "    plt.plot(X_test, reg.predict(X_test.reshape(-1, 1)), c='green', linewidth=4)\n",
    "    plt.title('{} trees'.format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(max_depth=1, learning_rate=1, warm_start=True)\n",
    "plt.figure(figsize=(20, 30))\n",
    "sizes = [1, 2, 5, 20, 100, 500, 1000, 2000]\n",
    "for i, s in enumerate(sizes):\n",
    "    reg.n_estimators = s\n",
    "    reg.fit(X_train.reshape(-1, 1), Y_train)\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.scatter(X_train, Y_train, s=30)\n",
    "    plt.plot(X_test, reg.predict(X_test.reshape(-1, 1)), c='green', linewidth=4)\n",
    "    plt.title('{} trees'.format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(max_depth=1, learning_rate=0.1, warm_start=True)\n",
    "plt.figure(figsize=(20, 30))\n",
    "sizes = [1, 2, 5, 20, 100, 500, 1000, 2000]\n",
    "for i, s in enumerate(sizes):\n",
    "    reg.n_estimators = s\n",
    "    reg.fit(X_train.reshape(-1, 1), Y_train)\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.scatter(X_train, Y_train, s=30)\n",
    "    plt.plot(X_test, reg.predict(X_test.reshape(-1, 1)), c='green', linewidth=4)\n",
    "    plt.title('{} trees'.format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ds = datasets.load_diabetes()\n",
    "X = ds.data\n",
    "Y = ds.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.5)\n",
    "\n",
    "MAX_ESTIMATORS = 250\n",
    "\n",
    "gbclf = GradientBoostingRegressor(warm_start=True)\n",
    "err_train_gb = []\n",
    "err_test_gb = []\n",
    "for i in range(1, MAX_ESTIMATORS+1):\n",
    "    gbclf.n_estimators = i\n",
    "    gbclf.fit(X_train, Y_train)\n",
    "    err_train_gb.append(1 - gbclf.score(X_train, Y_train))\n",
    "    err_test_gb.append(1 - gbclf.score(X_test, Y_test))\n",
    "\n",
    "gbclf = BaggingRegressor(warm_start=True)\n",
    "err_train_bag = []\n",
    "err_test_bag = []\n",
    "for i in range(1, MAX_ESTIMATORS+1):\n",
    "    gbclf.n_estimators = i\n",
    "    gbclf.fit(X_train, Y_train)\n",
    "    err_train_bag.append(1 - gbclf.score(X_train, Y_train))\n",
    "    err_test_bag.append(1 - gbclf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(err_train_gb, label='GB')\n",
    "plt.plot(err_train_bag, label='Bagging')\n",
    "plt.legend()\n",
    "plt.title('Train')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(err_test_gb, label='GB')\n",
    "plt.plot(err_test_bag, label='Bagging')\n",
    "plt.legend()\n",
    "plt.title('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand, randn\n",
    "\n",
    "set_size = 100\n",
    "lin_coef = 3\n",
    "sigma = 1\n",
    "\n",
    "X_train = (rand(set_size) * 10).reshape(-1, 1)\n",
    "Y_train = X_train * 3 + sigma * randn(set_size).reshape(-1, 1)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.scatter(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand, randn\n",
    "\n",
    "grid = np.arange(-1, 12, 0.1).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.scatter(X_train, Y_train)\n",
    "plt.plot(grid, lin_coef * grid, 'magenta')\n",
    "plt.plot(grid, lr.predict(grid), 'red',)\n",
    "plt.plot(grid, tree.predict(grid), 'green')\n",
    "plt.xlim([-1, 11])\n",
    "plt.legend(['Ground truth', 'Linear regression', 'Decision tree'], loc=0)\n",
    "print('LR train MSE = ', mean_squared_error(Y_train, lr.predict(X_train)))\n",
    "print('DT train MSE = ', mean_squared_error(Y_train, tree.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand, randn\n",
    "\n",
    "grid = np.arange(-1, 32, 0.1).reshape(-1, 1)\n",
    "\n",
    "X_test = (20 + rand(set_size) * 10).reshape(-1, 1)\n",
    "Y_test = X_test * 3 + sigma * randn(set_size).reshape(-1, 1)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.scatter(X_train, Y_train, c='blue')\n",
    "plt.scatter(X_test, Y_test, c='red')\n",
    "\n",
    "plt.plot(grid, lin_coef * grid, 'magenta')\n",
    "plt.plot(grid, lr.predict(grid), 'red',)\n",
    "plt.plot(grid, tree.predict(grid), 'green')\n",
    "plt.xlim([-1, 31])\n",
    "plt.legend(['Ground truth', 'Linear regression', 'Decision tree'], loc=0)\n",
    "\n",
    "print('LR train MSE = ', mean_squared_error(Y_train, lr.predict(X_train)))\n",
    "print('DT train MSE = ', mean_squared_error(Y_train, tree.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = -50 + 100 * np.random.rand(100, 2)\n",
    "Y = np.sign((X[:, 0] - 40) * X[:, 1])\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=100, cmap='summer',edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.5),\n",
    "                         np.arange(y_min, y_max, 0.5))\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=42, max_depth = i + 1)\n",
    "\n",
    "    clf.fit(X, Y)\n",
    "    xx, yy = get_grid(X)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='summer')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=30, cmap='summer',edgecolors='k')\n",
    "    plt.title('max_depth = ' + str(i + 1))\n",
    "    print('DT MSE (max_depth = ' + str(i+1) + ') = ', mean_squared_error(Y.reshape(-1, 1), clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "def plot_surface(X, y, clf):\n",
    "    h = 0.2\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,edgecolors='k')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=1)\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X, y)\n",
    "plot_surface(X, y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals = []\n",
    "for n in n_trees:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, max_depth=6, learning_rate=0.5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    q = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    quals.append(q)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals, marker='.')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals = []\n",
    "for n in n_trees:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, max_depth=6, learning_rate=0.03)\n",
    "    clf.fit(X_train, y_train)\n",
    "    q = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    quals.append(q)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals, marker='.')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals = []\n",
    "for n in n_trees:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, max_depth=2, learning_rate=0.03)\n",
    "    clf.fit(X_train, y_train)\n",
    "    q = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    quals.append(q)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals, marker='.')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
