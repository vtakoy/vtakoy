{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки (X_train): (404, 13)\n",
      "Размер тестовой выборки (X_test): (102, 13)\n",
      "Размер целевой переменной обучающей выборки (y_train): (404,)\n",
      "Размер целевой переменной тестовой выборки (y_test): (102,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузите данные\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Выделите целевую переменную\n",
    "X = data.drop(columns='MEDV')\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделите данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Выведите размеры полученных выборок\n",
    "print(\"Размер обучающей выборки (X_train):\", X_train.shape)\n",
    "print(\"Размер тестовой выборки (X_test):\", X_test.shape)\n",
    "print(\"Размер целевой переменной обучающей выборки (y_train):\", y_train.shape)\n",
    "print(\"Размер целевой переменной тестовой выборки (y_test):\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model   task        R2\n",
      "0     LR  task2  0.668483\n",
      "1  Ridge  task2  0.665961\n",
      "2  Lasso  task2  0.666869\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Загрузка данных и разделение\n",
    "data = pd.read_csv('boston.csv')\n",
    "X = data.drop(columns='MEDV')\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инициализация моделей\n",
    "lr_model = LinearRegression()\n",
    "ridge_model = Ridge()\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Обучение моделей\n",
    "lr_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Оценка моделей с использованием R²\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Обновление DataFrame с результатами\n",
    "results_regression = pd.DataFrame(columns=['model', 'task', 'R2'])\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model   task        R2\n",
      "3  Ridge_GridSearchCV  task3  0.668483\n",
      "4             RidgeCV  task3  0.668483\n",
      "5  Lasso_GridSearchCV  task3  0.668486\n",
      "6             LassoCV  task3  0.668486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Загрузка данных и разделение\n",
    "data = pd.read_csv('boston.csv')\n",
    "X = data.drop(columns='MEDV')\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Ridge Regression with GridSearchCV\n",
    "alphas_ridge = np.logspace(-4, 4, 10)  # Коэффициенты регуляризации для Ridge\n",
    "ridge_model = Ridge()\n",
    "grid_search_ridge = GridSearchCV(ridge_model, {'alpha': alphas_ridge}, cv=5, scoring='r2')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "best_ridge_model = grid_search_ridge.best_estimator_\n",
    "y_pred_ridge_grid_search = best_ridge_model.predict(X_test)\n",
    "r2_ridge_grid_search = r2_score(y_test, y_pred_ridge_grid_search)\n",
    "\n",
    "# 2. Ridge Regression with RidgeCV\n",
    "ridge_cv = RidgeCV(alphas=alphas_ridge, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "y_pred_ridge_cv = ridge_cv.predict(X_test)\n",
    "r2_ridge_cv = r2_score(y_test, y_pred_ridge_cv)\n",
    "\n",
    "# 3. Lasso Regression with GridSearchCV\n",
    "alphas_lasso = np.logspace(-4, 4, 10)  # Коэффициенты регуляризации для Lasso\n",
    "lasso_model = Lasso(max_iter=10000)\n",
    "grid_search_lasso = GridSearchCV(lasso_model, {'alpha': alphas_lasso}, cv=5, scoring='r2')\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "best_lasso_model = grid_search_lasso.best_estimator_\n",
    "y_pred_lasso_grid_search = best_lasso_model.predict(X_test)\n",
    "r2_lasso_grid_search = r2_score(y_test, y_pred_lasso_grid_search)\n",
    "\n",
    "# 4. Lasso Regression with LassoCV\n",
    "lasso_cv = LassoCV(alphas=alphas_lasso, cv=5, max_iter=10000)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "y_pred_lasso_cv = lasso_cv.predict(X_test)\n",
    "r2_lasso_cv = r2_score(y_test, y_pred_lasso_cv)\n",
    "\n",
    "# Обновление DataFrame с результатами\n",
    "results_regression = pd.DataFrame(columns=['model', 'task', 'R2'])\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   model   task        R2\n",
      "7   Ridge_StandardScaler  task4  0.668190\n",
      "8     Ridge_MinMaxScaler  task4  0.676221\n",
      "9   Lasso_StandardScaler  task4  0.624045\n",
      "10    Lasso_MinMaxScaler  task4  0.257392\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных и разделение\n",
    "data = pd.read_csv('boston.csv')\n",
    "X = data.drop(columns='MEDV')\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Ridge Regression with StandardScaler\n",
    "pipeline_ridge_standard = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "pipeline_ridge_standard.fit(X_train, y_train)\n",
    "y_pred_ridge_standard = pipeline_ridge_standard.predict(X_test)\n",
    "r2_ridge_standart_scaler = r2_score(y_test, y_pred_ridge_standard)\n",
    "\n",
    "# 2. Ridge Regression with MinMaxScaler\n",
    "pipeline_ridge_minmax = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "pipeline_ridge_minmax.fit(X_train, y_train)\n",
    "y_pred_ridge_minmax = pipeline_ridge_minmax.predict(X_test)\n",
    "r2_ridge_min_max_scaler = r2_score(y_test, y_pred_ridge_minmax)\n",
    "\n",
    "# 3. Lasso Regression with StandardScaler\n",
    "pipeline_lasso_standard = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(max_iter=10000))\n",
    "])\n",
    "pipeline_lasso_standard.fit(X_train, y_train)\n",
    "y_pred_lasso_standard = pipeline_lasso_standard.predict(X_test)\n",
    "r2_lasso_standart_scaler = r2_score(y_test, y_pred_lasso_standard)\n",
    "\n",
    "# 4. Lasso Regression with MinMaxScaler\n",
    "pipeline_lasso_minmax = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('lasso', Lasso(max_iter=10000))\n",
    "])\n",
    "pipeline_lasso_minmax.fit(X_train, y_train)\n",
    "y_pred_lasso_minmax = pipeline_lasso_minmax.predict(X_test)\n",
    "r2_lasso_min_max_scaler = r2_score(y_test, y_pred_lasso_minmax)\n",
    "\n",
    "# Обновление DataFrame с результатами\n",
    "results_regression = pd.DataFrame(columns=['model', 'task', 'R2'])\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model   task        R2\n",
      "11  Ridge_StandardScaler_CV  task5  0.667671\n",
      "12    Ridge_MinMaxScaler_CV  task5  0.672431\n",
      "13  Lasso_StandardScaler_CV  task5  0.668478\n",
      "14    Lasso_MinMaxScaler_CV  task5  0.668493\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных и разделение\n",
    "data = pd.read_csv('boston.csv')\n",
    "X = data.drop(columns='MEDV')\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение диапазона значений для alpha\n",
    "alphas = np.logspace(-4, 4, 10)\n",
    "\n",
    "# 1. Ridge Regression with StandardScaler and RidgeCV\n",
    "pipeline_ridge_standard_cv = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "pipeline_ridge_standard_cv.fit(X_train, y_train)\n",
    "y_pred_ridge_standard_cv = pipeline_ridge_standard_cv.predict(X_test)\n",
    "r2_ridge_standart_scaler_cv = r2_score(y_test, y_pred_ridge_standard_cv)\n",
    "\n",
    "# 2. Ridge Regression with MinMaxScaler and RidgeCV\n",
    "pipeline_ridge_minmax_cv = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('ridge', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "pipeline_ridge_minmax_cv.fit(X_train, y_train)\n",
    "y_pred_ridge_minmax_cv = pipeline_ridge_minmax_cv.predict(X_test)\n",
    "r2_ridge_min_max_scaler_cv = r2_score(y_test, y_pred_ridge_minmax_cv)\n",
    "\n",
    "# 3. Lasso Regression with StandardScaler and LassoCV\n",
    "pipeline_lasso_standard_cv = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', LassoCV(alphas=alphas, cv=5, max_iter=10000))\n",
    "])\n",
    "pipeline_lasso_standard_cv.fit(X_train, y_train)\n",
    "y_pred_lasso_standard_cv = pipeline_lasso_standard_cv.predict(X_test)\n",
    "r2_lasso_standart_scaler_cv = r2_score(y_test, y_pred_lasso_standard_cv)\n",
    "\n",
    "# 4. Lasso Regression with MinMaxScaler and LassoCV\n",
    "pipeline_lasso_minmax_cv = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('lasso', LassoCV(alphas=alphas, cv=5, max_iter=10000))\n",
    "])\n",
    "pipeline_lasso_minmax_cv.fit(X_train, y_train)\n",
    "y_pred_lasso_minmax_cv = pipeline_lasso_minmax_cv.predict(X_test)\n",
    "r2_lasso_min_max_scaler_cv = r2_score(y_test, y_pred_lasso_minmax_cv)\n",
    "\n",
    "# Обновление DataFrame с результатами\n",
    "results_regression = pd.DataFrame(columns=['model', 'task', 'R2'])\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model   task        R2\n",
      "15  Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16    Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17  Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18    Lasso_MinMaxScaler_Poly  task6  0.261126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных и разделение\n",
    "data = pd.read_csv('boston.csv')\n",
    "X = data.drop(columns='MEDV')\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение степени полинома\n",
    "poly_degree = 2\n",
    "\n",
    "# 1. Ridge Regression with StandardScaler and PolynomialFeatures\n",
    "pipeline_ridge_standard_poly = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "pipeline_ridge_standard_poly.fit(X_train, y_train)\n",
    "y_pred_ridge_standard_poly = pipeline_ridge_standard_poly.predict(X_test)\n",
    "r2_ridge_standart_scaler_poly = r2_score(y_test, y_pred_ridge_standard_poly)\n",
    "\n",
    "# 2. Ridge Regression with MinMaxScaler and PolynomialFeatures\n",
    "pipeline_ridge_minmax_poly = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "pipeline_ridge_minmax_poly.fit(X_train, y_train)\n",
    "y_pred_ridge_minmax_poly = pipeline_ridge_minmax_poly.predict(X_test)\n",
    "r2_ridge_min_max_scaler_poly = r2_score(y_test, y_pred_ridge_minmax_poly)\n",
    "\n",
    "# 3. Lasso Regression with StandardScaler and PolynomialFeatures\n",
    "pipeline_lasso_standard_poly = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False)),\n",
    "    ('lasso', Lasso(max_iter=10000))\n",
    "])\n",
    "pipeline_lasso_standard_poly.fit(X_train, y_train)\n",
    "y_pred_lasso_standard_poly = pipeline_lasso_standard_poly.predict(X_test)\n",
    "r2_lasso_standart_scaler_poly = r2_score(y_test, y_pred_lasso_standard_poly)\n",
    "\n",
    "# 4. Lasso Regression with MinMaxScaler and PolynomialFeatures\n",
    "pipeline_lasso_minmax_poly = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False)),\n",
    "    ('lasso', Lasso(max_iter=10000))\n",
    "])\n",
    "pipeline_lasso_minmax_poly.fit(X_train, y_train)\n",
    "y_pred_lasso_minmax_poly = pipeline_lasso_minmax_poly.predict(X_test)\n",
    "r2_lasso_min_max_scaler_poly = r2_score(y_test, y_pred_lasso_minmax_poly)\n",
    "\n",
    "# Обновление DataFrame с результатами\n",
    "results_regression = pd.DataFrame(columns=['model', 'task', 'R2'])\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение alpha для Ridge: 10\n",
      "R2 для Ridge: 0.8187344606117986\n",
      "Лучшее значение alpha для Lasso: 0.1\n",
      "R2 для Lasso: 0.8126678437365971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Создаем pipeline для Ridge регрессии\n",
    "pipe_ridge = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Масштабирование данных\n",
    "    ('poly', PolynomialFeatures(degree=2)),  # Создание полиномиальных признаков\n",
    "    ('ridge', Ridge())  # Ridge регрессия\n",
    "])\n",
    "\n",
    "# Создаем pipeline для Lasso регрессии\n",
    "pipe_lasso = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Масштабирование данных\n",
    "    ('poly', PolynomialFeatures(degree=2)),  # Создание полиномиальных признаков\n",
    "    ('lasso', Lasso(max_iter=10000, tol=0.01))  # Lasso регрессия с увеличением числа итераций и заданием tol\n",
    "])\n",
    "\n",
    "# Определяем сетку параметров для подбора\n",
    "param_grid_ridge = {\n",
    "    'ridge__alpha': [0.01, 0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "param_grid_lasso = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "# Настраиваем GridSearchCV для Ridge и Lasso\n",
    "grid_ridge = GridSearchCV(pipe_ridge, param_grid_ridge, cv=5, scoring='r2')\n",
    "grid_lasso = GridSearchCV(pipe_lasso, param_grid_lasso, cv=5, scoring='r2')\n",
    "\n",
    "# Обучаем модели на обучающих данных\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозируем и оцениваем R2 на тестовых данных\n",
    "y_pred_ridge = grid_ridge.predict(X_test)\n",
    "y_pred_lasso = grid_lasso.predict(X_test)\n",
    "\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Выводим результаты\n",
    "print(f\"Лучшее значение alpha для Ridge: {grid_ridge.best_params_['ridge__alpha']}\")\n",
    "print(f\"R2 для Ridge: {r2_ridge}\")\n",
    "\n",
    "print(f\"Лучшее значение alpha для Lasso: {grid_lasso.best_params_['lasso__alpha']}\")\n",
    "print(f\"R2 для Lasso: {r2_lasso}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'model': Ridge(max_iter=10000), 'model__alpha': 0.1, 'poly__degree': 3, 'scaler': MinMaxScaler()}\n",
      "R2 для лучшей модели: 0.859260813817776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Создаем pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Масштабирование данных\n",
    "    ('poly', PolynomialFeatures()),  # Создание полиномиальных признаков\n",
    "    ('model', Ridge())  # Модель регуляризации\n",
    "])\n",
    "\n",
    "# Определяем сетку параметров для подбора\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],  # Выбор метода масштабирования\n",
    "    'poly__degree': [1, 2, 3],  # Степень полинома\n",
    "    'model': [Ridge(max_iter=10000), Lasso(max_iter=10000), ElasticNet(max_iter=10000)],  # Модель с увеличенным числом итераций\n",
    "    'model__alpha': [0.01, 0.1, 1.0, 10, 100],  # Коэффициент регуляризации\n",
    "}\n",
    "\n",
    "# Настраиваем GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры модели\n",
    "best_params = grid_search.best_params_\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "\n",
    "# Прогнозируем и оцениваем R2 на тестовых данных\n",
    "y_pred_best = grid_search.predict(X_test)\n",
    "r2_best_model = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"R2 для лучшей модели: {r2_best_model}\")\n",
    "\n",
    "# Записываем результат\n",
    "results_regression = pd.DataFrame(columns=['Model', 'Task', 'R2'])\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Task</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Best_Model</td>\n",
       "      <td>task8</td>\n",
       "      <td>0.859261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model   Task        R2\n",
       "23  Best_Model  task8  0.859261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop('class', axis=1)  # Признаки (все столбцы, кроме 'class')\n",
    "y = data['class']  # Целевая переменная (столбец 'class')\n",
    "\n",
    "# Замена значений целевой переменной на числовые\n",
    "y = y.map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Вывод первых 5 строк для проверки\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy для самого частого класса: 0.7607182343065395\n",
      "F1 Score для самого частого класса: 0.8640999104619929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Определение самого частого класса\n",
    "most_frequent_class = y.mode()[0]\n",
    "\n",
    "# Создание предсказаний, основанных на самом частом классе\n",
    "y_pred_most_frequent = [most_frequent_class] * len(y)\n",
    "\n",
    "# Рассчет метрик\n",
    "acc_most_frequent = accuracy_score(y, y_pred_most_frequent)\n",
    "f1_most_frequent = f1_score(y, y_pred_most_frequent)\n",
    "\n",
    "# Запись результата\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1', 'Accuracy'])\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]\n",
    "\n",
    "# Вывод метрик для проверки\n",
    "print(f\"Accuracy для самого частого класса: {acc_most_frequent}\")\n",
    "print(f\"F1 Score для самого частого класса: {f1_most_frequent}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в каждом столбце:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n",
      "Количество пропусков после заполнения:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Проверка наличия пропусков в данных\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Количество пропусков в каждом столбце:\\n\", missing_values)\n",
    "\n",
    "# Если в данных присутствуют пропуски, заполним их самыми частыми значениями\n",
    "if missing_values.any():\n",
    "    # Создание объекта SimpleImputer для заполнения пропусков самыми частыми значениями\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    # Применение импера к данным\n",
    "    data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "    \n",
    "    # Обновление исходного набора данных\n",
    "    data = data_imputed\n",
    "\n",
    "# Проверка, что пропуски были заполнены\n",
    "missing_values_after = data.isnull().sum()\n",
    "print(\"Количество пропусков после заполнения:\\n\", missing_values_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые столбцы:\n",
      " Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "Категориальные столбцы:\n",
      " Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Выбор числовых столбцов\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "print(\"Числовые столбцы:\\n\", numeric_columns)\n",
    "\n",
    "# Выбор категориальных столбцов\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "print(\"Категориальные столбцы:\\n\", categorical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education-num      int64\n",
      "marital-status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital-gain       int64\n",
      "capital-loss       int64\n",
      "hours-per-week     int64\n",
      "native-country    object\n",
      "dtype: object\n",
      "Evaluating LogisticRegression...\n",
      "Evaluating KNeighborsClassifier...\n",
      "Evaluating LinearSVC...\n",
      "                  Model    Task  F1 Score  Accuracy\n",
      "0    LogisticRegression  task13  0.917387  0.870726\n",
      "1  KNeighborsClassifier  task13  0.887423  0.824311\n",
      "2             LinearSVC  task13  0.907260  0.856476\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Замена значений '?' на NaN\n",
    "data.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Убедитесь, что все данные правильно заменены\n",
    "print(data.head())\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Проверка типов данных\n",
    "print(X.dtypes)\n",
    "\n",
    "# Приведение всех данных к строкам (для обработки пропусков)\n",
    "X = X.astype(str)\n",
    "\n",
    "# Выбор числовых и категориальных столбцов\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Заполнение пропусков\n",
    "    ('scaler', MinMaxScaler())  # Масштабирование\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Заполнение пропусков\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Кодирование категориальных признаков\n",
    "])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Определение моделей\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=10000),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Оценка моделей\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Проверка данных перед запуском cross_val_score\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        f1_scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1')\n",
    "        acc_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "        \n",
    "        f1_mean = f1_scores.mean()\n",
    "        acc_mean = acc_scores.mean()\n",
    "        \n",
    "        results_classification.loc[len(results_classification)] = [model_name, 'task13', f1_mean, acc_mean]\n",
    "    except ValueError as e:\n",
    "        print(f\"Error evaluating {model_name}: {e}\")\n",
    "\n",
    "print(results_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Model    Task  F1 Score  Accuracy\n",
      "0    LogisticRegression_impute  task14  0.904841  0.850805\n",
      "1  KNeighborsClassifier_impute  task14  0.887331  0.825232\n",
      "2             LinearSVC_impute  task14  0.905419  0.851255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Заменяем '?' на np.nan для дальнейшей обработки\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Приведение целевой переменной к целочисленному типу\n",
    "y = y.astype(int)\n",
    "\n",
    "# Выбор числовых и категориальных столбцов\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Создание трансформеров для числовых и категориальных данных с учетом замены пропусков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Создание ColumnTransformer для обработки различных типов данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Создание моделей\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Метрики для оценки моделей\n",
    "scoring = {'accuracy': 'accuracy', 'f1': 'f1'}\n",
    "\n",
    "# Инициализация переменных для хранения результатов\n",
    "results_classification = []\n",
    "\n",
    "# Оценка моделей с помощью cross_validate\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=5, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc_mean = cv_results['test_accuracy'].mean()\n",
    "    \n",
    "    # F1 Score\n",
    "    f1_mean = cv_results['test_f1'].mean()\n",
    "    \n",
    "    # Запись результатов\n",
    "    results_classification.append({\n",
    "        'Model': model_name + '_impute',\n",
    "        'Task': 'task14',\n",
    "        'F1 Score': f1_mean,\n",
    "        'Accuracy': acc_mean\n",
    "    })\n",
    "\n",
    "# Преобразование в DataFrame\n",
    "results_classification_df = pd.DataFrame(results_classification)\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model    Task  F1 Score  Accuracy\n",
      "0    LogisticRegression_delete_missings  task15  0.901356  0.847176\n",
      "1  KNeighborsClassifier_delete_missings  task15  0.882938  0.820552\n",
      "2             LinearSVC_delete_missings  task15  0.902416  0.848525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Удаление строк с пропущенными значениями ('?')\n",
    "data.replace('?', pd.NA, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Приведение целевой переменной к целочисленному типу\n",
    "y = y.astype(int)\n",
    "\n",
    "# Выбор числовых и категориальных столбцов\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Создание трансформеров для числовых и категориальных данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Создание ColumnTransformer для обработки различных типов данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Создание моделей\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Метрики для оценки моделей\n",
    "scoring = {'accuracy': 'accuracy', 'f1': 'f1'}\n",
    "\n",
    "# Инициализация списка для хранения результатов\n",
    "results_list = []\n",
    "\n",
    "# Оценка моделей с помощью cross_val_score\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    # Accuracy\n",
    "    acc_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "    acc_mean = acc_scores.mean()\n",
    "    \n",
    "    # F1 Score\n",
    "    f1_scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1')\n",
    "    f1_mean = f1_scores.mean()\n",
    "    \n",
    "    # Запись результатов\n",
    "    results_list.append({\n",
    "        'Model': model_name + '_delete_missings',\n",
    "        'Task': 'task15',\n",
    "        'F1 Score': f1_mean,\n",
    "        'Accuracy': acc_mean\n",
    "    })\n",
    "\n",
    "# Преобразование списка в DataFrame\n",
    "results_classification = pd.DataFrame(results_list)\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Model    Task  Mean Accuracy\n",
      "0      RandomForestClassifier_with_frequent_values  task16       0.851296\n",
      "1  GradientBoostingClassifier_with_frequent_values  task16       0.866386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Заменяем '?' на np.nan и затем на самые частые значения для каждого столбца\n",
    "data.replace('?', pd.NA, inplace=True)\n",
    "data.fillna(data.mode().iloc[0], inplace=True)\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Приведение целевой переменной к целочисленному типу\n",
    "y = y.astype(int)\n",
    "\n",
    "# Выбор числовых и категориальных столбцов\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Создание трансформеров для числовых и категориальных данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Создание ColumnTransformer для обработки различных типов данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Создание моделей\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Метрики для оценки моделей\n",
    "scoring = 'accuracy'  # Вы можете использовать любую другую метрику по вашему выбору\n",
    "\n",
    "# Инициализация списка для хранения результатов\n",
    "results_list = []\n",
    "\n",
    "# Оценка моделей с помощью cross_val_score\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring=scoring)\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # Запись результатов\n",
    "    results_list.append({\n",
    "        'Model': model_name + '_with_frequent_values',\n",
    "        'Task': 'task16',\n",
    "        'Mean Accuracy': mean_score\n",
    "    })\n",
    "\n",
    "# Преобразование списка в DataFrame\n",
    "results_classification = pd.DataFrame(results_list)\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загружаем файл CSV\n",
    "df = pd.read_csv('house_prices.csv')\n",
    "\n",
    "# Выводим список столбцов\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
