{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dH7qx_irU4Y8"
   },
   "source": [
    "###ML1_1: \n",
    "https://www.hackerrank.com/challenges/capturing-non-capturing-groups/problem?isFullScreen=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Введите строку: okok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадение найдено!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Ввод строки\n",
    "test_string = input(\"Введите строку:\")\n",
    "\n",
    "# Регулярное выражение для поиска двух или более \"ok\" подряд\n",
    "pattern = r'(ok){2,}'\n",
    "\n",
    "# Проверка на совпадение\n",
    "if re.search(pattern, test_string):\n",
    "    print(\"Совпадение найдено!\")\n",
    "else:\n",
    "    print(\"Совпадение не найдено.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ML1_2: \n",
    "https://www.hackerrank.com/challenges/branch-reset-groups/problem?isFullScreen=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Введите строку:  12.34.56.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадение найдено!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Ввод строки\n",
    "test_string = input(\"Введите строку: \")\n",
    "\n",
    "# Регулярное выражение для проверки строки\n",
    "pattern = r'^\\d{2}([-:.]|---)\\d{2}\\1\\d{2}\\1\\d{2}$'\n",
    "\n",
    "# Проверка на совпадение\n",
    "if re.match(pattern, test_string):\n",
    "    print(\"Совпадение найдено!\")\n",
    "else:\n",
    "    print(\"Совпадение не найдено.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ML1_3: \n",
    "https://www.hackerrank.com/challenges/detect-html-links/problem?isFullScreen=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  2\n",
      " <p><a href=\"https://www.hackerrank.com\">Example Link</a></p>\n",
      " <div><a href=\"https://www.hackerrank.com/another\">Another Link</a></div>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hackerrank.com,Example Link\n",
      "https://www.hackerrank.com/another,Another Link\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "\n",
    "# Чтение количества строк HTML-фрагмента\n",
    "n = int(input())\n",
    "\n",
    "# Чтение всех строк HTML-фрагмента\n",
    "html_content = ''.join([input().strip() for _ in range(n)])\n",
    "\n",
    "# Создание объекта BeautifulSoup для разбора HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Проход по всем тегам <a>\n",
    "for link in soup.find_all('a', href=True):\n",
    "    # Извлечение ссылки\n",
    "    href = link['href'].strip()\n",
    "    # Извлечение текста внутри тега, очищенного от вложенных тегов\n",
    "    text = link.get_text().strip()\n",
    "    # Печать результата\n",
    "    print(f\"{href},{text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJfkstKpqsXp"
   },
   "source": [
    "###ML1_4: \n",
    "Реализовать stemming, lemmatization & BoW на следующем датасете: https://cloud.mail.ru/public/Z4L3/vB8GcgTtK (Russian Toxic-abuse comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  \\\n",
      "0               Верблюдов-то за что? Дебилы, бл...\\n   \n",
      "1  Хохлы, это отдушина затюканого россиянина, мол...   \n",
      "2                          Собаке - собачья смерть\\n   \n",
      "3  Страницу обнови, дебил. Это тоже не оскорблени...   \n",
      "4  тебя не убедил 6-страничный пдф в том, что Скр...   \n",
      "\n",
      "                                     stemmed_comment  \\\n",
      "0                      верблюдов то за что дебилы бл   \n",
      "1  хохлы это отдушина затюканого россиянина мол в...   \n",
      "2                              собаке собачья смерть   \n",
      "3  страницу обнови дебил это тоже не оскорбление ...   \n",
      "4  тебя не убедил 6 страничный пдф в том что скри...   \n",
      "\n",
      "                                  lemmatized_comment  \n",
      "0                      верблюдов то за что дебилы бл  \n",
      "1  хохлы это отдушина затюканого россиянина мол в...  \n",
      "2                              собаке собачья смерть  \n",
      "3  страницу обнови дебил это тоже не оскорбление ...  \n",
      "4  тебя не убедил 6 страничный пдф в том что скри...  \n",
      "   00  000  0015  003  0036  005  00х  01  013  02  ...  ёлка  ёлку  ёмаё  \\\n",
      "0   0    0     0    0     0    0    0   0    0   0  ...     0     0     0   \n",
      "1   0    0     0    0     0    0    0   0    0   0  ...     0     0     0   \n",
      "2   0    0     0    0     0    0    0   0    0   0  ...     0     0     0   \n",
      "3   0    0     0    0     0    0    0   0    0   0  ...     0     0     0   \n",
      "4   0    0     0    0     0    0    0   0    0   0  ...     0     0     0   \n",
      "\n",
      "   ёмкостей  ёмкости  ёмкость  ёмкостью  ёпта  ёта  ётавских  \n",
      "0         0        0        0         0     0    0         0  \n",
      "1         0        0        0         0     0    0         0  \n",
      "2         0        0        0         0     0    0         0  \n",
      "3         0        0        0         0     0    0         0  \n",
      "4         0        0        0         0     0    0         0  \n",
      "\n",
      "[5 rows x 68387 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(r'C:\\Users\\vtako\\Desktop\\Project\\NPL homework 1\\labeled.csv', sep=',')\n",
    "\n",
    "# Инициализация стеммера и лемматизатора\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Функция предобработки текста\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Удаление всех небуквенных символов\n",
    "    text = text.lower()  # Приведение к нижнему регистру\n",
    "    return text\n",
    "\n",
    "# Функция для токенизации\n",
    "def simple_tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "# Функция для стемминга\n",
    "def apply_stemming(text):\n",
    "    words = simple_tokenize(text)  # Использование простого токенизатора\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Функция для лемматизации\n",
    "def apply_lemmatization(text):\n",
    "    words = simple_tokenize(text)  # Использование простого токенизатора\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Применение предобработки\n",
    "data['cleaned_comment'] = data['comment'].apply(preprocess_text)\n",
    "\n",
    "# Применение стемминга\n",
    "data['stemmed_comment'] = data['cleaned_comment'].apply(apply_stemming)\n",
    "\n",
    "# Применение лемматизации\n",
    "data['lemmatized_comment'] = data['cleaned_comment'].apply(apply_lemmatization)\n",
    "\n",
    "# Пример использования BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(data['lemmatized_comment'])\n",
    "\n",
    "# Преобразование в DataFrame\n",
    "bow_df = pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Вывод первых строк после обработки\n",
    "print(data[['comment', 'stemmed_comment', 'lemmatized_comment']].head())\n",
    "print(bow_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP1_homework",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
